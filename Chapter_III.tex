Unless otherwise specified, in the following $R = (R,+,\cdot)$ denotes an arbitrary ring \emph{with identity} (the book assumes this throughout this book), $0, 1$ denotes the additive and multiplicative identity of $R$, respectively. In the case of possible confusion, I will use $0_R, 1_R$ instead. 

Some description and hints are omitted for simplicity.

\section{}

\begin{problem}{III.1.1}
Prove that if $0 = 1$ in a ring $R$, then $R$ is a zero ring.
\end{problem}
\begin{proof}
If $r$ is any element in $R$, then
\[
r = r \cdot 1 = r \cdot 0 = 0  
\]
showing that $R = 0$.
\end{proof}
\begin{problem}{III.1.6}
Prove that if $a$ and $b$ are nilpotent in $R$ and $ab = ba$, then so is $a+b$.
\end{problem}
\begin{proof}
If $a^n = 0, b^m = 0$, then
\[
(a+b)^{n+m} = a^{n+m} +\binom{n+m-1}{1} a^{n+m-1}b + \dotsc + b^{n+m}
\]
and all terms are zeros since every term either have $a^n$ or $b^m$. If we do not assume that $ab = ba$, then the statement would be false, for example, in $M_n(\Z)$,
\[
\begin{pmatrix} 
1 & 0 \\
1 & 0
\end{pmatrix}
\quad \text{and} \quad
\begin{pmatrix} 
0 & 1 \\
0 & 1 
\end{pmatrix}
\]
are nilpotent of degree $3$, but
$\begin{pmatrix} 
1 & 0 \\
1 & 0
\end{pmatrix} + 
\begin{pmatrix} 
0 & 1 \\
0 & 1 
\end{pmatrix} = 
\begin{pmatrix} 
1 & 1 \\
1 & 1
\end{pmatrix}$ is not nilpotent.
\end{proof}

\begin{problem}{III.1.7}
Prove that $[m]$ is nilpotent in $\Z/n\Z$ if and only if $m$ is divisible by all prime factors of $n$. 
\end{problem}
\begin{proof}

\noindent $(\Rightarrow)$ If $[m]^k = [0]$ for some integer $k$, then this implies $m^k = dn$ for some integer $d$. Now we write $n = p_1^{a_1} \cdots p_n^{a_n}$, where $p_i$ are primes, and $a_i$ are positive integers. Then
\[
m^k = d p_1^{a_1} \cdots p_n^{a_n}
\]
and it is clear to see that $m$ must contain each $p_i$ at least once. \\
$(\Leftarrow)$ If $n = p_1^{a_1} \cdots p_n^{a_n}$ where $p_i$ are primes, and $a_i$ are positive integers, then we can write 
\[
m = p_1^{b_1} \cdots p_n^{b_n} d
\] 
where $b_i, d$ are positive integers, and $p_i \nmid d$ for all $i$. Define 
\[
f = \text{floor}\left(\max\left\{ \frac{a_1}{b_1}, \cdots \frac{a_n}{b_n}\right\} \right)    
\]
then let $r = m^f/n$, which is an integer larger than 0 by the choice of $f$. Finally
\[
m^f = nr = 0 \mod n
\]
showing that $m$ is nilpotent in $\Z/n\Z$.
\end{proof}

\begin{problem}{III.1.9}
Prove Proposition 1.12, that is:
\textit{
\begin{itemize}
\setlength\itemsep{0pc}
\item The inverse of a two-sided unit is unique;
\item two-sided units form a group under multiplication.
\end{itemize}
}
\end{problem}
\begin{proof}
For a two-sided unit $v$, we have $uv = 1$ and $vw = 1$ for some $u,w \in R$. Then 
\[
w = 1 \cdot w = uvw = u \cdot 1 = u    
\]
showing that $w = u$, so the inverse can be uniquely defined as $v^{-1} = u$. Now as the inverse is unique, we can define a group structure, using the multiplication from the ring $R$. We check that
\begin{itemize}
	\setlength\itemsep{0pt}
	\item $1$ is a unit as $1 \cdot 1 = 1$;
	\item for a unit $u$, $u^{-1}$ is also a unit;
	\item associativity is clear.
\end{itemize}
\end{proof}

\begin{problem}{III.1.15}
Prove that $R[x]$ is a domain if and only if $R$ is a domain.
\end{problem}
\begin{proof} \

\noindent $(\Rightarrow)$ Trivial since $R \subset R[x]$. \\
$(\Leftarrow)$ Assume the contrary that $R[x]$ is not a domain. Then we can find $f = \sum_{i=0}^n a_ix^i, \: g = \sum_{j=0}^m b_jx^j$, $f \neq 0, g \neq 0$ such that $fg = 0$. Then we would have $a_nb_m = 0$, and since $R$ is a domain, either $a_n$ or $b_m$ is zero. Without loss of generality, we can reduce the case to $f = a_0 \neq 0$. Then by the same argument, we would arrive at $a_0b_0 = 0$, since all higher terms must be zero. But this contradict to the assumption that $R$ is a domain, since $f = a_0$ and $g = b_0$ are nonzero. Hence $R[x]$ must be a domain.
\end{proof}

\section{}
\begin{problem}{III.2.1}
Prove that if there is a homomorphism from a zero ring to a ring $R$, then $R$ is a zero ring.
\end{problem}
\begin{proof}
If $1_R$ is the multiplicative identity of $R$, then for any homomorphism $\varphi : 0 \to R$, 
\[
0_R = \varphi(0) = \varphi(1) = 1_R
\]
and by \ref{III.1.1}, $R$ is a zero-ring.
\end{proof}

\begin{problem}{III.2.6}
Verify the 'extension property' of polynomial ring:

\textit{
Let $\alpha : R \to S$ be a fixed ring homomorphism, and let $s \in S$ be an element commuting with $\alpha(r)$ for all $r \in R$. Then there is a unique ring homomorphism $\bar{\alpha} : R[x] \to S$ extending $\alpha$ and sending $x$ to $s$.
}
\end{problem}
\begin{proof}
Indeed, for $\sum_{i \geq 0} a_ix^i \in R[x]$, we have no choice but to define
\[
\bar{\alpha}\left(\sum_{i \geq 0} a_ix^i\right) = \sum_{i \geq 0}\alpha(a_i)s^{i}  \tag{1}
\]
so that $\bar{\alpha}(r) = \alpha(r)$ and $x$ sends to $s$ in this map. It is clearly a homomorphism (note that the commutativity of $s$ is used in the proof of $\bar{\alpha}(fg) = \bar{\alpha}(f)\bar{\alpha}(g)$), so it suffices to check that $\bar{\alpha}$ is unique. But it is clear by the fact that any map that extends $\alpha$ and send $x$ to $s$ must have the same value evaluated as in $(1)$.
\end{proof}

\begin{problem}{III.2.9}
Prove that the center of $R$ is a subring. Moreover, prove that the center of a division ring is a field.
\end{problem}
\begin{proof}
A subset of a ring $S$ is a subring if it is a subgroup of $(R,+)$, closed under multiplication, and $1$ is in it. So we check that:
\begin{itemize}
\setlength\itemsep{0pt}
\item it is a subgroup of $(R,+)$: for $a,b \in C$, for all $r \in R$,
\[
(a-b)r = ar - br = ra - rb = r(a-b)    
\]
showing that $a-b \in C$, hence a subgroup;
\item closed under multiplication: for $a,b \in C$, for all $r \in R$,
\[
abr = a(br) = a(rb) = (ar)b = (ra)b = rab     
\]
showing that $ab \in C$;
\item finally, $1$ is in $C$ since $1r = r1$ for all $r \in R$.
\end{itemize}


Clearly the center forms a commutative ring since for $a,b \in C$, $ab = ba$. Then it follows by definition that a commutative division ring is a field. 
\end{proof}

\begin{problem}{III.2.10}
Prove that the centralizer of $a$ is a subring for every $a \in R$. Prove that the center is the intersection of all its centralizers, and prove that every centralizer of a division ring is a division ring.
\end{problem}
\begin{proof}
We use the same test as above. Let $C_x$ denotes the centralizer of $x$.
\begin{itemize}
\setlength\itemsep{0pt}
\item It is a subgroup of $(R,+)$: for $a,b \in C_x$,
\[
(a-b)x = ax - bx = xa - xb = x(a-b)    
\]
showing that $a-b \in C_x$, hence a subgroup;
\item closed under multiplication: for $a,b \in C_x$,
\[
abx = a(bx) = a(xb) = (ax)b = (xa)b = xab     
\]
showing that $ab \in C_x$;
\item finally, $1$ is in $C_x$ since $1x = x1$.
\end{itemize}
It is easy that the center is the intersection of all its centralizers, since such elemet in the intersection must commute with the whole ring $R$. Finally, if $R$ is a division ring, then for every element $a \in C_x$, we can show that $a^{-1} \in C_x$:
\[
ax = xa \Rightarrow axa^{-1} = x \Rightarrow xa^{-1} = a^{-1}x
\]
Therefore every element in $C_x$ has a inverse, and by definition, $C_x$ is a division ring.
\end{proof}

\begin{problem}{III.2.11}
Prove that a division ring $R$ which consists of $p^2$ elements where $p$ is a prime, is commutative. 
\end{problem}
\begin{proof}
Suppose the contrary that $R$ is not commutative. Then the center $C$ must be a proper subring, which can only consist of $p$ elements by Lagrange. Now let $r \in R \backslash C$. Then the centralizer of $r$ will contain at least $r$ and $C$ by III.2.10, therefore the centralizer of $r$ must be $R$ itself (again by Lagrange), for every $r \in R \backslash C$. But then the intersection of all centralizer are now $R$ (element of center has centralizer $R$ clearly), which is a contradiction to that $C$ is proper. Therefore $R$ must be commutative, i.e. a field.
\end{proof}

\begin{problem}{III.2.12}
Consider the inclusion map $\iota : \Z \xhookrightarrow{} \Q$. Describe the cokernel of $\iota$ in \textsf{Ab} and its cokernel in \textsf{Ring}.
\end{problem}
\begin{solution}
In \textsf{Ab}, this is easy: it is just $\Q/\im \iota = \Q / \Z$. However in \textsf{Ring}, we notice that for any map $\alpha : \Q \to F$ that satisfy $\alpha \circ \iota = 0$, we have
\[
0_F = \alpha (1) = \alpha \circ \iota (1) = \alpha (1) = 1_F  
\] 
which shows that $F$ must be the zero ring by \ref{III.1.1}. Now the unique homomorphism $\bar{\alpha} :\text{coker } \iota \to F$ must also be the zero map, and by the requirement $\bar{\alpha} \circ \pi \circ \iota = 0$, we finally have $\pi \circ \iota = 0$, and by the same argument as above, we have that the codomain of $\pi$ is the zero ring, i.e. $\text{coker } \iota = 0$.
\end{solution}

\section{}

\begin{problem}{III.3.2}
Let $\varphi:R \to S$ be a ring homomorphism, and let $J$ be an ideal of $S$. Prove that $\varphi^{-1}(J)$ is an ideal.
\end{problem}
\begin{proof}
The ideal is clearly nonempty, so it suffices to check that $\varphi^{-1}(J)$ is a additive subgroup and satisfies the absorption property. For $x, y \in \varphi^{-1}(J)$, we have $\varphi(x), \varphi(y) \in J$, so $\varphi(x)-\varphi(y) = \varphi(x-y) \in J$, therefore $x-y \in \varphi^{-1}(J)$, showing that it is a subgroup of $(R,+)$.

Now for any $r \in R, a \in \varphi^{-1}(J)$, we have $\varphi(a) \in J$, so $\varphi(r)\varphi(a) = \varphi(ra) \in J$, and hence $ra \in \varphi^{-1}(J)$, showing the left-absorption property. The right case is the same.
\end{proof}

\begin{problem}{III.3.3}
Let $\varphi : R \to S$ be a ring homomorphism, and let $J$ be an ideal of $R$.
\end{problem}
\begin{itemize}
\setlength\itemsep{0pt}
\item Show that $\varphi(J)$ need not be an ideal of $S$.
\item Assume that $\varphi$ is surjective; then prove that $\varphi(J)$ \emph{is} an ideal of $S$.
\item Assume that $\varphi$ is surjective, and let $I = \ker \varphi$. Let $\bar{J} = \varphi(J)$. Prove that 
\[
\frac{R/I}{\bar{J}} \cong \frac{R}{I+J}.	
\]
\end{itemize}
\begin{proof}
Let $\varphi : \Z \xhookrightarrow{} \R$ be inclusion (and clearly a homomorphism). Then every ideal of $\Z$ will be directly transformed into $\R$. But since $\R$ is a field, by III.3.8 (which will be proved later) the possible ideal of $\R$ are only $\{0\}$ and $\R$ itself, so the image of a homomorphism need not to be an ideal.

However, If $\varphi$ is surjective, Then $\varphi(J)$ is indeed an ideal: if $\varphi(x), \varphi(y) \in \varphi(J)$, then so is $\varphi(x) - \varphi(y) = \varphi(x-y) \in \varphi(J)$. The absorption property is also true since $\varphi(r)\varphi(x) = \varphi(rx) \in \varphi(J)$.

Finally, we consider the homomorphism
\[
\phi : R/I \to R/(I+J), \quad \phi(a + I) = a + I + J
\]
$\phi$ is clearly a surjective homomorphism, and by first isomorphism theorem
\[
\frac{R/I}{\ker \phi} \cong \frac{R}{I+J}	
\]
so it remains to solve $\ker \phi$, which is
\begin{align*}
\ker \phi &= \{a + I : a + I + J = I + J\} \\
&= \{a +b + I : a \in I, b \in J\} \\
&= \{b + I : b \in J\} \\
&= \{\varphi(b) \in S : b \in J\} \quad \text{(regarding } R/I \text{ as } S)\\
&= \varphi(J) = \bar{J}
\end{align*}
therefore
\[
\frac{R/I}{\bar{J}} \cong \frac{R}{I+J}
\]
as required.
\end{proof}

\begin{problem}{III.3.7}
Let $R$ be a ring, and let $a \in R$. Prove that $Ra$ is a left-ideal of $R$ and $aR$ is a right-ideal of $R$. Prove that $a$ is a left-, resp. right-, unit if and only if $R = aR$, resp. $R = Ra$.
\end{problem}
\begin{proof}
We prove only the left-ideal case since the same argument holds for right-ideal case. $Ra$ is a subgroup of $(R,+)$ since for $ra, sa \in Ra$, $ra - sa = (r-s)a \in Ra$. The absorption property follows easily since $rsa = (rs)a \in Ra$.

If $a$ is a right unit, then there exists $u$ such that $ua = 1$. Then $1$ is contained in $Ra$, and since for all $r\in R$, $r \cdot 1 \in Ra$, we conclude that $R = Ra$.   
\end{proof}

\begin{problem}{III.3.8}
Prove that $R$ is a division ring if and only if its only left-ideals and right-ideals are $\{0\}$ and $R$.

In particular, a commutative ring $R$ is a field if and only if the only ideals of $R$ are $\{0\}$ and $R$.
\end{problem}
\begin{proof}

\noindent $(\Rightarrow)$ If a nonzero element $a$ is in the left-ideal $I$, then so is $1$ since 
\[
1 = a^{-1}a \in I \text{ by definition}
\] 
Therefore any nonzero left-ideals are automatically $R$ itself. The right-ideal case is the same.

\noindent $(\Leftarrow)$ If a nonzero element $a$ does not have a left inverse, then $aR$ would be a proper right-ideal by III.3.7. Therefore all elements must have left(and hence right) inverse.
\end{proof}

\begin{problem}{III.3.10}
Let $\varphi : k \to R$ be a ring homomorphism, where $k$ is a field and $R$ is a nonzero ring. Prove that $\varphi$ is \emph{injective}.
\end{problem}
\begin{proof}
$\varphi$ is injective if and only if $\ker \varphi = \{0\}$ by Proposition III.2.4. Also, the ideals of $k$ are only $\{0\}$ and $k$ by III.3.8. If $\ker \varphi = \{0\}$ then there is nothing to prove, so let $\ker \varphi = k$. But this means that $\varphi = 0$, so we have
\[
1_R = \varphi(1) = 0 = \varphi(0) = 0_R    
\]
and by III.1.1, $R$ is a zero ring, a contradiction to the hypothesis. Therefore $\ker \varphi = \{0\}$, showing that $\varphi$ is injective.
\end{proof}


\begin{problem}{III.3.12}
Let $R$ be a \emph{commutative} ring. Prove that the set of nilpotent elements forms an ideal of $R$. This ideal is called the \emph{nilradical} of $R$.
\end{problem}
\begin{proof}
From \ref{III.1.6} we already know that it forms a subgroup of $(R,+)$ by relpacing $b$ with $-b$, so it remains to check that it is an ideal. Let $I$ be such ideal. If $a \in R, r \in I$ and $r^n = 0$, then since
\[
(ar)^n \overset{!}{=} a^nr^n = 0    
\]
in which ! is where commutativity is used. Therefore $ar \in I$, proving the absorption property.

For an counter-example where $R$ is not commutative, simply consider the example of III.1.6: it is not even a subgroup of $(R, +)$.
\end{proof}

\begin{problem}{III.3.13}
Let $R$ be a commutative ring, and let $N$ be its nilradical. Prove that $R/N$ contains no nonzero nilpotent elements. Such a ring is said to be \emph{reduced}.
\end{problem}
\begin{proof}
Pick an element $a \in R \backslash N$. Then for every integer $n > 0$, 
\[
(a + N)^n = a^n + \binom{n}{1} a^{n-1} N + \cdots + N^n = a^n + N
\]
Since $a$ is not nilpotent, $a^n \neq 0$ for every $n$, showing that $a + N$ is not nilpotent for $a \in R \backslash N$.
\end{proof}

\section{}
\begin{problem}{III.4.1}
Let $R$ be a ring, and let $\{I_\alpha\}_{\alpha \in A}$ be a family of ideals of $R$. We let 
\[
\sum_{\alpha \in A} I_\alpha := \left\{ \sum_{\alpha \in A}r_\alpha \text{ such that } r_\alpha \in I_\alpha \text{ and } r_\alpha = 0 \text{ for all but finitely many } \alpha \right\}.  
\]
Prove that $\{I_\alpha\}_{\alpha \in A}$ is an ideal of $R$ and that it is the smallest ideal containing all of the ideals $I_\alpha$.
\end{problem}
\begin{proof}
We only consider the case when $A = \{1,2\}$: Any other $A$ follows the same exact argument. 

Let $I = I_1 + I_2$. $I$ is a subgroup of $(R,+)$ : the two elements in $I$ can be represented as $r_1 + r_2$ and $r'_1 + r'_2$, and clearly $(r_1 - r'_1) + (r_2 - r'_2)$ is in $I$. The absorption property is also clear, since $r (r_1 + r_2) = (rr_1 + rr_2) \in I$. 

Now it suffice to show that $I$ is minimal. For every ideal that contains $I_1$ and $I_2$, they must also contain $r_1 + r_2$ for $r_1 \in I_1$ and $r_2 \in I_2$, since ideal is a subgroup of $(R,+)$. Therefore every such ideal must also contain $I$, proving the minimality of $I$.
\end{proof}

\begin{problem}{III.4.2}
Prove that the homomorphic image of a Noetherian ring is Noetherian.
\end{problem}
\begin{proof}
Let $R$ be Noetherian, $S$ be any ring, $\varphi:R \to S$ be a surjective ring homomorphism. Let $J$ be an ideal of $S$. By \ref{III.3.2}, the preimage is an ideal, which we call $I = \langle a_1, \dotsc,  a_n \rangle$. We claim that $J = \langle \varphi(a_1), \dotsc, \varphi(a_n) \rangle$, so every finitely generated ideal will map to a finitely generated ideal, proving that $S$ is Noetherian. 

Indeed, since $a_i \in \varphi^{-1}(J)$, $\varphi(a_i) \in J$ for $i = 1,\dotsc,n$, so $\langle \varphi(a_1), \dotsc \varphi(a_n) \rangle \subseteq J$. On the other hand, for an element $j \in J$, there exists $i \in R$ such that $\varphi(i) = j$ by surjectivity, therefore $i \in I$, so $i$ is generated by elements $a_1, \dotsc ,a_n$, i.e. $i = r_1a_1 + \cdots + r_na_n$. Then since $\varphi$ is a homomorphism, 
\[
\varphi(i) = j = \varphi(r_1a_1 + \cdots + r_na_n) = s_1\varphi(a_1) + \cdots + s_n\varphi(a_n)
\]
so $J \subseteq \langle \varphi(a_1), \dotsc \varphi(a_n) \rangle$, and the claim is proved.
\end{proof}

\begin{problem}{III.4.3}
Prove that the ideal $(2,x)$ of $\Z[x]$ is not principal. 
\end{problem}
\begin{proof}
Assume that $(f) = (2,x)$. Then there is some $q \in \Z[x]$ such that $fq = 2$. Then $f,q$ are constant and $f$ must be $2$ since $1$ is not in it. But we also have $fg = x$ for some $g \in Z[x]$, and there are no possible choice of $g$ such that $2g = x$. Hence $(2,x)$ is not principal.
\end{proof}

\begin{problem}{III.4.4}
Prove that if $k$ is a field, then $k[x]$ is a PID.
\end{problem}
\begin{proof}
Let $I$ be any ideal of $k[x]$. If $I = (0)$, then there is nothing to prove. Otherwise, there is some polynomial $f\in I$ that has minimal degree in $I$ and is monic (since you can do scalar division). We claim that $I = (f)$. Indeed, for $g \in I$, we can use division algorithm to write
\[
g(x) = f(x)q(x) + r(x)  
\]  
where $\deg r(x) < \deg f(x)$. Since $k[x]$ is a subgroup, $r = g - fq \in I$, and by the minimality of $f$, $r(x) = 0$, so every element of $I$ can be written as $g(x)f(x)$ for some $g \in k[x]$, showing that $k[x]$ is a PID.
\end{proof}

\begin{problem}{III.4.5}
Let $I, J$ be ideals in a commutative ring $R$, such that $I+J = (1)$. Prove that $IJ = I \cap J$.
\end{problem}
\begin{proof}
If $x \in IJ$, then it can be represented as $ij$ for some $i \in I, j \in J$, and by the property of ideal, $ji \in I, ij \in J$, so $ij \in I \cap J$. Conversely, we have
\[
I \cap J = (I \cap J) (1) = (I\cap J)(I+J) = (I \cap J)I + (I \cap J)J \subseteq IJ + IJ = IJ 
\]
showing the identity.
\end{proof}

\begin{problem}{III.4.7}
Let $R = k$ be a field. Prove that every nonzero (principle) ideal in $k[x]$ is generated by a unique \emph{monic} polynomial.
\end{problem}
\begin{proof}
From III.4.4 we already know that every ideal is generated by a single polynomial $f$. Since $k$ is a field, we can do division, so there is a monic polynomial $f(x)/a$ where $a$ is the coefficient of the largest degree in $f$. Then it's trivial that $(f) = (f/a)$.
\end{proof}

\begin{problem}{III.4.10}
Let $d$ be an integer that is not the square of an integer, and consider the subset of $\C$ defined by 
\[
\Q(\sqrt{d}) := \{a+b\sqrt{d} \;| \; a,b \in \Q\}	
\] 
\begin{itemize}
    \setlength\itemsep{0pt}
    \item Prove that $\Q(\sqrt{d})$ is a subring of $\C$.
    \item Define a function $N:\Q(\sqrt{d}) \to \Z$ by $N(a+b\sqrt{d}) := a^2 - b^2d$. Prove that $N(zw) = N(z)N(w)$ and that $N(z)\neq 0$ if $z \in \Q(\sqrt{d}), z \neq 0$. $N$ is called a \emph{norm}.
    \item Prove that $\Q(\sqrt{d})$ is a field and in fact the smallest subfield of $\C$ containing both $\Q$ and $\sqrt{d}$.
    \item Prove that $\Q(\sqrt{d}) \cong \Q[t]/(t^2-d)$.
\end{itemize}
\end{problem}
\begin{proof}\
\begin{itemize}
    \item Subring property is clear by $a+b\sqrt{d} - (c+d\sqrt{d}) = (a-c) + (b-d)\sqrt{d} \in \Q(\sqrt{d})$.
    \item If $N(a+b\sqrt{d}) = 0$, then $a^2 = b^2d$, and since $d$ is not a square, $a$ cannot be a rational number, so $a = 0 = b$. The multiplicative property is easily checked by 
    \begin{align*}
    N((a+b\sqrt{d})(m+n\sqrt{d})) &= (am+bnd)^2 - (an+bm)^2d \\
    &= (am)^2 - (an)^2d - (bm)^2d + (bnd)^2 +2ambnd-2ambnd \\
    &= (a^2-b^2d)(m^2-n^2d) = N(a+b\sqrt{d})N(m+n\sqrt{d})
    \end{align*}
    \item An inverse of $a+b\sqrt{d}$ is
    \[
    \frac{1}{a+b\sqrt{d}} = \frac{1}{a^2-b^2d}\left(a-b\sqrt{d}\right).
    \]
    \item The homomorphism
    \[
    \varphi: \Q[t] \to \Q(\sqrt{d}), \quad \varphi(f(x)) = f(\sqrt{d})	
    \]
    has kernel $(t^2-d)$, and the result is immediate by first isomorphism theorem. 
\end{itemize}
\end{proof}

\begin{problem}{III.4.11}
Let $R$ be a commutative ring, $a \in R$, and $f_1(x),\dotsc,f_r(x) \in R[x]$.
\begin{itemize}
\setlength\itemsep{0pt}
\item Prove the equality of ideals
\[
(f_1(x),\dotsc,f_r(x),x-a) = (f_1(a),\dotsc,f_r(a),x-a).
\]
\item Prove the useful substitution trick
\[
\frac{R[x]}{(f_1(x),\dotsc,f_r(x),x-a)} \cong \frac{R}{(f_1(a),\dotsc,f_r(a))}
\]
\end{itemize}
\end{problem}
\begin{proof}
We consider only the case $k = 1$; the other cases are just extending the same argument. We are required to prove that 
\[
(f(x), x-a) = (f(a), x-a)
\]
For $f(x)$, we can apply division algorithm to get
\[
f(x) = q(x)(x-a) + r
\]
where $q(x) \in R[x], r \in R$. By plug in $x = a$, we obtain $r = f(a)$. Therefore $f(x)$ is generated by $f(a)$ and $(x-a)$, showing $f(x)\in (f(a), x-a)$. On the other hand, note the division algorithm also implies
\[
f(a) = f(x) - q(x)(x-a) \in (f(x), x-a)
\]
therefore $f(a) \in (f(x), x-a)$, so $(f(x), x-a) = (f(a), x-a)$. Now since $R[x]/(x-a) \cong R$, by III.3.3
\[
\frac{R}{\varphi(J)} \cong \frac{R[x]}{\ker \varphi + J}	
\]
for an ideal $J \in R[x]$, $\varphi : R[x] \to R$ a surjective homomorphism. It is clear that how should we choose these: by taking
\[
J = (f_1(x),\dotsc,f_r(x)), \quad \varphi(f(x)) = f(a)	
\]
we have
\[
\frac{R}{(f_1(a),\dotsc,f_r(a))} \cong \frac{R[x]}{(f_1(x),\dotsc,f_r(x),x-a)} 
\]
as desired (note that $\varphi$ is surjective).
\end{proof}

\begin{problem}{III.4.13}
Let $R$ be an integral domain. For all $k = 1,\dotsc, n$, prove that $(x_1,\dotsc, x_k)$ is prime in $R[x_1,\dotsc, x_n]$.
\end{problem}
\begin{proof}
We proceed by induction. For the case $k = 1$, we have
\[
\frac{R[x]}{(x)} \cong R	\quad \text{(p.p.151)}
\]
and since $R$ is a domain, it follows by definition that $(x)$ is a prime ideal. Suppose that for $k < n$, the argument holds. Then for $k = n$, choose
\[
J = (x_1,\dotsc,x_{n-1}), \quad \varphi : R[x_1,\dotsc,x_{n}] \xhookrightarrow{} R[x_1,\dotsc,x_{n-1}]
\]
where $\varphi$ is the inclusion map and $\ker \varphi = (x_n)$. Then by \ref{III.3.3}
\[
\frac{R[x_1,\dotsc,x_{n}]/(x_n)}{(x_1,\dotsc,x_{n-1})} \cong \frac{R[x_1,\dotsc,x_{n}]}{(x_1,\dotsc,x_{n-1})+(x_n)}
\]
which simplifies to
\[
\frac{R[x_1,\dotsc,x_{n-1}]}{(x_1,\dotsc,x_{n-1})} \cong \frac{R[x_1,\dotsc,x_{n}]}{(x_1,\dotsc,x_n)}	
\]
By induction hypothesis, the quotient on the left is a domain since $(x_1,\dotsc,x_{n-1})$ is a prime ideal, therefore by definition, $(x_1,\dotsc,x_n)$ is a prime ideal.
\end{proof}


\begin{problem}{III.4.16}
Let $R$ be a commutative ring, and let $P$ be a prime ideal of $R$. Suppose $0$ is the only zero-divisor of $R$ contained in $P$. Prove that $R$ is an integral domain. 
\end{problem}
\begin{proof}
Let $a,b \in R$ such that $ab = 0$. Then since $0 \in P$, $ab \in P$, so either $a\in P$ or $b \in P$. Without loss of generality, let $a \in P$. If $a = 0$, then we are done; otherwise, $a \neq 0$, and since $ab = 0$, we must have $b = 0$ as $a$ is not a zero divisor ($0$ is the only zero-divisor in $P$). In both cases, we show that $ab = 0$ implies $a = 0$ or $b = 0$, showing that $R$ is a domain.
\end{proof}

\begin{problem}{III.4.18}
Let $R$ be a commutative ring, and let $N$ be its nilradical (III.3.12). Prove that $N$ is contained in every prime ideal of $R$.
\end{problem}
\begin{proof}
Let $x^n = 0$ for some positive integer $n$, and $P$ a prime ideal. Then since $0 \in P$, we have
\[
P \ni 0 = x^n = x \cdot x^{n-1}
\]
By the property of prime ideal, either $x \in P$ or $x^{n-1}$ in $P$. If the former case is true, then we are done; else, we can reduce to the case where either $x \in P$ or $x^{n-2} \in P$. By continuing this process, we will arrive at either $x \in P$ or $x \in P$, showing that in any cases, $x \in P$. Therefore all nilpotent elements are in $P$, proving the statement. 
\end{proof}

\begin{problem}{III.4.21}
Let $k$ be an algebraic closed field, and let $I \subseteq k[x]$ be an ideal. Prove that $I$ is maximal if and only if $I = (x-c)$ for some $c \in k$.
\end{problem}
\begin{proof}

\noindent $(\Leftarrow)$ We have 
\[
\frac{k[x]}{(x-c)} \cong k 	\quad \text{(p.p.151)}	
\]
and since $k$ is a field, it follows by definition that $(x-c)$ is maximal. \\
$(\Rightarrow)$ Let $J$ be a maximal ideal. By \ref{III.4.4}, $k[x]$ is a PID, hence every ideal is being generated by a single \emph{monic} polynomial $f(x) \in k[x]$ (\ref{III.4.7}). Since $k$ is algebraic closed, we can write $f(x) = q(x)(x-c)$ for some $q(x) \in k[x],\; c \in k$. Then  
\[
J = (f(x)) = (q(x)(x-c)) \subseteq (x-c)
\]
and by Proposition III.4.11, either $J = (x-c)$ or $J = k[x]$. The latter case could not happen since the maximal can not be $k[x]$ itself, therefore $J = (x-c)$, as desired. 
\end{proof}

Unless otherwise specified, in the following $M$ denotes a (left-)module over $R$.

\section{}

\begin{problem}{III.5.2}
Prove claim 5.1.
\end{problem}
\begin{proof}
Let $\sigma : R \to \text{End}_\mathsf{Ab}(M)$ be a ring homomorphism and $\rho : R \times M \to M$ a function. We verify the following properties:
\begin{itemize}
\setlength\itemsep{0pt}
\item $\rho(r,m+n) = \rho(r,m) + \rho(r,n)$. \\
Note that $\sigma(r)$ is a endomorphism on $M$. Then 
\[
\rho(r,m+n) = \sigma(r)(m+n) = \sigma(r)(m) + \sigma(r)(n) = \rho(r,m) + \rho(r,n)	
\] 
\item $\rho(r+s, m) = \rho(r,m) + \rho(s,m)$. 
\[
\rho(r+s, m) = \sigma(r+s)(m) = \sigma(r)(m) + \sigma(s)(m) = \rho(r,m) + \rho(s,m)
\]
\item $\rho(rs,m) = \rho(r,\rho(s,m))$. 
\[
\rho(rs,m) = \sigma(rs)(m) = \sigma(r)\sigma(s)(m) = \sigma(r)\rho(s,m) = \rho(r,\rho(s,m))
\]
\item $\rho(1,m) = m$. 
\[
\rho(1,m) = \sigma(1)(m) = 1(m) = m	
\]
\end{itemize}
\end{proof}

\begin{problem}{III.5.3}
Prove that $0\cdot m = 0$ and that $(-1) \cdot m = -m$ for all $m \in M$. 
\end{problem}
\begin{proof}
Since $0m = (0+0)m = 0m + 0m, 0m = 0$. Since $0 = 0m = (-1+1)m = (-1)m+m, (-1)m = -m$.
\end{proof}

\begin{problem}{III.5.4}
Let $R$ be a ring. A nonzero $R$-module $M$ is \emph{simple} (or \emph{irreducible}) if its only 
submodules are $\{0\}$ and $M$. Let $M, N$ be simple modules, and let $\varphi: M \to N$ be 
a homomorphism of $R$-modules. Prove that either $\varphi = 0$ or $\varphi$ is an isomorphism. 
\end{problem}
\begin{proof}
The kernel of a $R$-module homomorphism is a submodule of $M$, which can only be $\{0\}$ or $M$. If $\ker \varphi = M$ then $\varphi = 0$, and if $\ker \varphi = \{0\}$ then $\varphi$ is injective. The image of a $R$-module homomorphism is a submodule of $N$, which again can only be $\{0\}$ or $M$. if $\im \varphi = \{0\}$ then $\varphi = 0$, and if $\im \varphi = N$ then $\varphi$ is surjective. 

So there are four different combination of images and kernels:
\begin{itemize}
    \setlength\itemsep{0pt}
    \item $\ker \varphi = M, \im \varphi = \{0\} \Rightarrow \varphi = 0$;
    \item $\ker \varphi = M, \im \varphi = N \Rightarrow \varphi = 0, N = 0$, which can't be by hypothesis;
    \item $\ker \varphi = \{0\}, \im \varphi = \{0\} \Rightarrow \varphi = 0, M = 0$, which can't be by hypothesis;
    \item $\ker \varphi = \{0\}, \im \varphi = N \Rightarrow \varphi$ is an isomorphism.
\end{itemize}
so either $\varphi = 0$ or $\varphi$ is an isomorphism. 
\end{proof}

\begin{problem}{III.5.5}
Let $R$ be a commutative ring, viewed as an $R$-module over itself, and let $M$ be an $R$-module. Prove that $\Hom_{R\textsf{-Mod}}(R,M) \cong M$ as $R$-modules.
\end{problem}
\begin{proof}
Every module homomorphism $f: R \to M$ is uniquely determined by the result of $f(1)$ (which is a unit). Therefore 
\begin{align*}
    \Hom_{R\textsf{-Mod}}(R,M) &\to M \\
    f &\mapsto f(1)
\end{align*}
is an isomorphism of $R$-modules.
\end{proof}

\begin{problem}{III.5.11}
Let $R$ be commutative, and let $M$ be an $R$-module. Prove that there is a natural bijection between the set of $R[x]$-module structures on $M$ (extending the given $R$-module structure) and $\text{End}_{R-\mathsf{Mod}}(M)$.
\end{problem}
\begin{proof}
If $f \in \text{End}_{R-\textsf{Mod}}(M)$, then we have to show that there are some suitable maps
\begin{align*}
R[x] \times M &\to M \\
(f(x), \:m) &\to \: ?
\end{align*}
that makes $M$ into a $R[x]$-module. We consider $(g(x),m) \to g(f)(m)$, where if $g(x) = \sum_i a_i x^i$, then
\[
\sigma(f,m) = \sum_{i} a_i f^i(m) \text{ where } f^i = \underbrace{f \circ \cdots \circ f}_{i\text{ times}}
\]
We can easily check by definition that $M$ is a $R[x]$-module. Conversely, if $M$ is a $R[x]$-module, then define $f(m) = xm$. Then $f$ is indeed an endomorphism (note that the commutativity of $R$ ensures that $rxm = xrm$ for $r \in R$, so $f$ is an endomorphism), proving the statement.
\end{proof}

\begin{problem}{III.5.12}
Let $M,N$ be $R$-modules, and let $\varphi:M \to N$ be a homomorphism of $R$-modules which has a inverse (therefore a bijection). Prove that $\varphi^{-1}$ is also a homomorphism of $R$-modules. Conclude that a bijective $R$-module homomorphism is a $R$-module isomorphism.
\end{problem}
\begin{proof}
Since
\[
\varphi(\varphi^{-1}(m) + \varphi^{-1}(n)) = m + n = \varphi(\varphi^{-1}(m + n))
\]
we have $\varphi^{-1}(m) + \varphi^{-1}(n) = \varphi^{-1}(m + n)$. And
\[
\varphi(r\varphi^{-1}(m)) = r\varphi(\varphi^{-1}(m)) = rm = \varphi(\varphi^{-1}(rm))
\]
so $r\varphi^{-1}(m) = \varphi^{-1}(rm)$ indeed. 
\end{proof}


\begin{problem}{III.5.14}
Prove Proposition 5.18, that is:

\textit{Let $N,P$ be submodules of an $R$-module $M$. Then
\begin{itemize}
\setlength\itemsep{0pt}
\item $N+P$ is a submodule of $M$;
\item $N \cap P$ is a submodule of $P$, and
\[
\frac{N+P}{N} \cong \frac{P}{N \cap P}.	
\]
\end{itemize}
}
\end{problem}
\begin{proof}
Every element of $N+P$ can be written as $n+p$ where $n \in N, p \in P$. Then it is clear that $r(n+p)$ = $rn + rp \in N+P$ for $r \in M$. For the intersection $N \cap P$, it is also clear that for $p \in P, n \in N \cap P$, $pr \in N$ since $r \in N$, and $pr \in P$ since $p \in P$.

The proof for the second isomorphism theorem follows exactly the same as in groups (Proposition II.8.11). Consider the homomorphism
\[
\varphi: P \to \frac{N+P}{N}, \quad \varphi(p) = pN	
\]
it is surjective since for every $(n+p)N$, there is a corresponding $p$. Then
\[
\ker \varphi = \{p \in P : p \in N\} = P \cap N	
\]
finally it follows by first isomorphism theorem that 
\[
\frac{N+P}{N} \cong \frac{P}{N \cap P}.
\]
\end{proof}

\section{}

\begin{problem}{III.6.1}
Prove Claim 6.3, that is, $F^R(A) \cong R^{\oplus A}$.
\end{problem}
\begin{proof}
Observe that every element in $R^{\oplus A}$ can be uniquely written as
\[
\sum_{a \in A}r_a \chi(a)	
\]
where $\chi(a) = \chi_a(x)$, the indicator function of $a$, and $r_a \in R$ for $a \in A$. Then it suffices to check the universal property of free modules: given a function $f : A \to M$ where $M$ is a module, we show that the following diagram 
\[
\begin{tikzcd}
R^{\oplus A} \arrow[r, "\exists!\varphi"] & M \\
A \arrow[u, "\chi"] \arrow[ru, "f"']      &  
\end{tikzcd}
\]
commutes. Indeed, we define
\[
\varphi\left(\sum_{a \in A}r_a \chi(a)\right) = \sum_{a \in A}r_a f(a)
\]
then the diagram clearly commutes (and is unique). Finally, $\varphi$ is a $R\mathsf{-Mod}$ homomorphism since 
\begin{align*}
\varphi\left(\sum_{a \in A}r_a \chi(a)\right) + \varphi\left(\sum_{a \in A}r_a' \chi(a)\right) = \sum_{a \in A}r_a f(a) + \sum_{a \in A}r_a' f(a)\overset{\checkmark}{=} \sum_{a \in A}(r_a+r_a') f(a) \\
= \varphi\left(\sum_{a \in A}(r_a+r_a') \chi(a)\right) = \varphi\left(\sum_{a \in A}r_a \chi(a) + \sum_{a \in A}r_a' \chi(a)\right)	
\end{align*}
Note that $R$-module's definition gurantees the commutativity of $\checkmark$ (scalar multiplication is direct).
\end{proof}

\begin{problem}{III.6.3}
Let $R$ be a ring, $M$ an $R$-module, and $p : M \to M$ an $R$-module homomorphism such that $p^2 = p$. Prove that $M \cong \ker p \oplus \im p$.
\end{problem}
\begin{proof}
We are required to prove that the diagram
\[
\begin{tikzcd}[column sep=large]
\ker p \arrow[rd, "i_k"] \arrow[rrd, "f_k", bend left]  &                                &   \\
& M \arrow[r, "\exists!\varphi"] & N \\
\im p  \arrow[ru, "i_m"'] \arrow[rru, "f_m"', bend right] &                                &  
\end{tikzcd}
\]
commutes. Notice that for $x \in \ker p, p(x) = 0$, and
\[
\text{ for } x \in \im p, x - p(x) = p(y) - p(p(y)) = p(y) - p(y) = 0
\]
where $p(y) = x$. This suggest that we define $\varphi$ as 
\[
\varphi(x) = f_k(x - p(x)) + f_m(p(x))
\]
Indeed, if $x \in \ker p$, then $\varphi(x) = f_k(x)$; if $x \in \im p$, then $\varphi(x) = f_m(p(x)) = f_m(x)$ since for $x \in \im p$,
\[
p(y) = x, p(p(y)) = p(y) \Rightarrow p(x) = x.	
\]
But what about $x \in \ker p \cap \im p$? In fact, the only element in the intersection is $0$, as such $x$ must have
\[
x = p(y) = p(p(y)) = p(x) = 0
\]
so $\varphi$ is well-defined. Now it suffices to check that $\varphi$ is a homomorphism, which is direct since $p, f_k$ and $f_m$ are both $R$-homomorphisms, so it preserves the action on $M$ (check yourself if you're not convinced). Therefore by the universal property of coproduct, $\ker p \oplus \im p \cong M$.
\end{proof}

\begin{problem}{III.6.4}
Let $R$ be a ring, and let $n > 1$. View $R^{\oplus(n-1)}$ as a submodule of $R^{\oplus n}$, via the injective homomorphism $R^{\oplus(n-1)} \xhookrightarrow{} R^{\oplus n}$ defined by
\[
(r_1,\dotsc,r_{n-1}) \xhookrightarrow{}	(r_1,\dotsc,r_{n-1}, 0).
\]
Give a one-line proof that
\[
\frac{R^{\oplus n}}{R^{\oplus (n-1)}} \cong R.	
\] 
\end{problem}
\begin{proof}
The surjective map
\[
(r_1,\dotsc,r_{n-1}, r_n) \twoheadrightarrow r_n.
\]
has kernel precisely $R^{\oplus (n-1)}$, therefore by first isomorphism theorem
\[
\frac{R^{\oplus n}}{R^{\oplus (n-1)}} \cong R.	
\]  
\end{proof}

\begin{problem}{III.6.5}
For any ring $R$ and any two sets $A_1, A_2$, prove that $(R^{\oplus A_1})^{\oplus A_2} \cong R^{\oplus(A_1 \times A_2)}$.
\end{problem}
\begin{proof}
By \ref{III.6.1}, it is equivalent to prove the following diagram commutes:
\[
\begin{tikzcd}
(R^{\oplus A_1})^{\oplus A_2} \arrow[r, "\exists!\varphi"] & M \\
A_1 \times A_2 \arrow[ru, "f"'] \arrow[u, "j"]             &  
\end{tikzcd}
\]
To do this, note that an element in $(R^{\oplus A_1})^{\oplus A_2}$ is a function $g : A_2 \to R^{\oplus A_1}$, in which we send an element $a_2 \in A_2$ to 
\[
j_{a_1, a_2}(x) := \begin{cases}
1 &\text{ if } x = a_1 \\
0 &\text{ if } x \neq a_1 
\end{cases}	\quad \text{(p.p.168)}
\]
this suggests us to define
\[
j(a_1,a_2) \mapsto (j_{a_1,a_2}(b_2))(b_1) = \chi_{a_1}(b_1)\chi_{a_2}(b_2)	
\]
where $\chi$ is the indicator function. Then it follows the same pattern as in III.6.1: for $f : A_1 \times A_2 \to M$ given and any element $\sum_{a_1 \in A_1, a_2 \in A_2} r_{a_1,a_2} (j_{a_1,a_2}(b_2))(b_1) \in (R^{\oplus A_1})^{\oplus A_2}$, define
\[
\varphi \left(\sum_{a_1 \in A_1, a_2 \in A_2} r_{a_1,a_2} (j_{a_1,a_2}(b_2))(b_1)\right) = \sum_{a_1 \in A_1, a_2 \in A_2} r_{a_1,a_2} f(a_1,a_2)
\]
The commutativity of the diagram is direct. Finally, the check for $\varphi$ is a $R-\mathsf{Mod}$ homomorphism is the same as in \ref{III.6.1}.
\end{proof}

\begin{problem}{III.6.7}
Let $A$ be any set, and for any module $M$ over a ring $R$, define 
\[
M^A	:= \prod_{a \in A}M, \quad M^{\oplus A} := \bigoplus_{a \in A}M.
\]
Prove that $\Z^\N \ncong \Z^{\oplus \N}$.
\end{problem}
\begin{proof}
Note that $\Z^\N$ can be regarded as the collection of functions
\[
f: \Z \to \N 
\]
which is the collection of all infinite sequences in $\Z$. This set has uncountably many elements (as one can argue using Cantor's diagonal argument). On the other hand, $\Z^{\oplus \N}$ is also the collection of these function, but with the additional criterion that
\[
f(n) = 0 \text{ for all but finitely many }	n \in Z
\]
which says that this set collects all finite sequence in $\Z$, and as we know (i.e. can construct a bijection to $\Z$), this set is countable. As the cardinality does not match, $\Z^\N \ncong \Z^{\oplus \N}$, as required.
\end{proof}

\begin{problem}{III.6.9}
Let $R$ be a ring, $F$ a nonzero free $R$-module, and let $\varphi: M \to N$ be a homomorphism of $R$-modules. Prove that $\varphi$ is onto if and only if for all $R$-module homomorphisms $\alpha: F \to N$ there exists an $R$-module homomorphism $\beta:F \to M$ such that $\alpha = \varphi \circ \beta$.
\end{problem}
\begin{proof}
As $M$ is free, it is generated by a set $X = \{x_i\}$ (not necessarily finite). 

\noindent $(\Rightarrow)$ Let $\{n_i\} \in N$ be such that $\varphi(x_i) = n_i$. If $\varphi$ is onto, then each $n_i$ corresponds to a $m_i \in M$ such that $\varphi(m_i) = n_i$. We then just define $\beta(x_i) = m_i$, and the commutativity is clear (note that $\beta$ might not be unique, but that's fine). \\
$(\Leftarrow)$ If $\varphi$ is not onto, i.e. there exists $n \in N$ such that $n \notin \im \varphi$, then this also means that $n \notin \im (\varphi \circ \beta)$ for any $\beta$. Now we choose a suitable $\alpha$ so $\alpha = \varphi \circ \beta$ does not hold. Indeed, we can define
\[
\alpha(x_i) = n	
\]
for all $i$. Then the commutativity does not hold for any choice of $\beta$, a contradiction. Therefore $\varphi$ must be surjective.
\end{proof}


\begin{problem}{III.6.10}
Let $M,N,$ and $Z$ be $R$-modules, and let $\mu:M \to Z, \nu:N \to Z$ be homomorphism of $R$-modules. Prove that $R-\mathsf{Mod}$ has 'fibered products'(cf. Exercise \ref{I.5.12}).
\end{problem}
\begin{proof}
As in the case \textsf{Set}(I.5.12), we define fibered coproduct to be  the set of elements that agrees on $Z$ after being pushed by $\mu$ and $\nu$:
\[
M \times_Z N := \{(m,n)\in M \oplus N:m\in M, n \in N, \mu(m) = \nu(n)\}
\]
By the universal property of fibered product on \textsf{Set}, the diagram with the \emph{set-function} $\varphi(z) := (f_M(z),f_N(z))$ makes the following diagram 
\[
\begin{tikzcd}
P \arrow[rd, "\exists!\varphi", dashed] \arrow[rdd, "f_M"', bend right] \arrow[rrd, "f_N", bend left] & & \\
& M \times_Z N \arrow[d, "\pi_M"] \arrow[r, "\pi_N"'] & N \arrow[d, "\nu"] \\
& M \arrow[r, "\mu"']  & Z                    
\end{tikzcd}    
\]
commutes, regarding in \textsf{Set}. Now we check that $M \times_Z N$ indeed is a submodule of $M \oplus N$: for $(m,n) \in M \times_Z N$, $r (m,n) = (rm,rn)$, and since $\mu(m)=\nu(n)$, $r\mu(m) = \mu(rm) = \nu(rn) = r\nu(n)$, so $(rm,rn) \in M \times_Z N$ as required.	

Now it remains to check $\varphi$ is a $R$-module homomorphism, which is direct.
\end{proof}

\begin{problem}{III.6.11}
Define a notion of \emph{fibered coproduct} of two $R$-modules $M, N$, along an $R$-module $A$, in the style of Exercise III.6.10 (and cf. \ref{I.5.12}).

Prove that fibered coproducts exist in $R$-\textsf{Mod}. The fibered coproduct $M \oplus_A N$ is called the \emph{push-out} of $M$ along $\nu$ (or of $N$ along $\mu$).
\end{problem}
\begin{proof}
The universal property is as the same stated in I.5.12, but by replacing every set with $R$-modules and every morphism with $R\mhyphen\mathsf{Mod}$ homomorphisms. We now show that the fibered coproduct is almost the same in \textsf{Set}: define an equivalence relation
\[
S = \{(\mu(x), \nu(x)) \in M \oplus N : x \in A\}
\]
on $M \oplus N$, and let $M \oplus_A N := (M \oplus N)/S$. We show that $R$ is a submodule, so the quotient make sense. For $(m,n) \in S$,
\[
r(m,n) = r(\mu(x),\nu(x)) = (r\mu(x), r\nu(x)) = (\mu(rx), \nu(rx)) \in S	
\]
which shows that $S$ is indeed an $R$-module. Now define
\[
\varphi((m,n)+R) = f_M(m) + f_N(n)	
\]
It is a simple check that $\varphi$ is a $R$-module homomorphism, and $\varphi$ is well-defined, using the same argument as in \textsf{Set}(I.5.12). This makes the following diagram 
\[
\begin{tikzcd}
A \arrow[r, "\nu"] \arrow[d, "\mu"']       & N \arrow[d, "i_N"] \arrow[rdd, "f_N", bend left]          &   \\
M \arrow[r, "i_M"'] \arrow[rrd, "f_M", bend right] & M \oplus_A N \arrow[rd, "\exists!\varphi", dashed] &   \\
&                                                    & Z
\end{tikzcd}	
\]
commutes, as we check:
\begin{itemize}
\item $i_N \nu = i_M \mu$:
\[
i_N \nu (x) = (0, \nu(x)) + S = (\mu(x), 0) + S = i_M \mu(x)
\]
\item $f_M = \varphi i_M $ (resp. $f_N = \varphi i_N$):
\[
\varphi	i_M (m) = \varphi((m,0)+S) = f_M(m).
\]
\end{itemize}
\end{proof}



\begin{problem}{III.6.14}
Prove that the ideal $(x_1,x_2,\dotsc)$ of the ring $R = \Z[x_1,x_2,\dotsc]$ is not finitely generated (as an ideal, i.e. as an $R$-module).
\end{problem}
\begin{proof}
If it were, then there exists a surjective $R\mhyphen\mathsf{Mod}$ homomorphism
\[
\varphi : R^{\oplus n} \twoheadrightarrow (x_1,x_2,\dotsc).
\]
Then we collect the polynomials 
\[
\{\varphi(0,\dotsc,\underset{i\text{-th place}}{1},\dotsc,0)\}_{i = 1}^n	
\]
Since each polynomials can only contain finitely many indeterminates, and there are only finite polynomials, there must be some indeterminates $x_j$ that is not in the domain of $\varphi$ (as there are countably many indeterminates in the ideal), contradicting to the surjectivity of $\varphi$. Therefore $(x_1,x_2,\dotsc)$ is not finitely generated.
\end{proof}

\begin{problem}{III.6.16}
Let $R$ be a ring. A (left-)$R$-module $M$ is \emph{cyclic} if $M = \langle m \rangle$ for some $m \in M$. Prove that simple modules (cf. Exercise \ref{III.5.4}) are cyclic. Prove that an $R$-module $M$ is cyclic if and only if $M \cong R/I$ for some (left-)ideal $I.$ Prove that 
every quotient of a cyclic module is cyclic. 
\end{problem}
\begin{proof}
By the universal property of free module there is a unique homomorphism of $R$-modules
\[
\varphi : R^{\{m\}} \to M	
\]
Since $M$ is simple, we can only have $\varphi(R^{\{m\}}) = 0$ or $\varphi(R^{\{m\}}) = M$. We definitely can't have $\varphi = 0$ unless $m = 0$, so $\varphi(R^{\{m\}}) = M = \langle m \rangle$ for $m \neq 0$. 

If $M = \langle m \rangle$, then we define a $R$-module homomorphism $\varphi: R \to M$ by $\varphi(r) = rm$. It is surjective by construction, and we have $M \cong R/\ker \varphi$.
Conversely if $M \cong R/I$, then there is a surjective $R$-module homomorphism $\varphi: R \to M$ such that its kernel is $I$. By identifing $R$ with $R^{\{m\}}$, the result is now clear.

The last statement follows from that you can restrict a surjective map $\varphi: R \to M$ to another surjective map $\varphi': R \to M/N$. 
\end{proof}

\begin{problem}{III.6.17}
Let $M$ be a cyclic $R$-module, so that $M \cong R/I$ for a (left-)ideal $I$, and let $N$ be another $R$-module.
\begin{itemize}
    \setlength\itemsep{0pt}
    \item Prove that $\Hom_{R\mhyphen \mathsf{Mod}}(M,N) \cong \{n \in N : (\forall a \in I), an = 0\}$.
    \item For $a, b \in \Z$, prove that $\Hom_{R \mhyphen \mathsf{Mod}}(\Z/a\Z, \Z/b\Z) \cong \Z/\gcd(a,b)\Z$.
\end{itemize}
\end{problem}
\begin{proof}
Every homomorphism $\varphi: M \to N$ is begin fixed by the generator of $M$, so we only need to investigate $\varphi(m)$ where $M = \langle m \rangle$. To make $\varphi$ into an $R$-module homomorphism, we must have
\[
\varphi(a+I+b+I) = \varphi(a+I) + \varphi(b+I) \quad \text{ and } \quad  r\varphi(a+I) = \varphi(ra+rI)	
\]
In particular, let $\varphi(m+I) = n$, where $m+I$ is the element identified by the generator $m$. Clearly we must have $\varphi(I) = 0$, and for $r \in R$ we have
\[
r\varphi(m+I) = \varphi(rm + I) = rn	
\]
so if $rm \in I$, i.e. $r \in I$, then $rn = 0$. So the set of all possibe $\varphi(m)$ coincide with the set on the right, showing the isomorphism. Now
\[
\Hom_{R \mhyphen \mathsf{Mod}}(\Z/a\Z, \Z/b\Z) \cong \{n \in \Z/b\Z : (\forall a \in a\Z) an = 0\}
\]
which is precisely $Z/\gcd(a,b)\Z$.
\end{proof}

\begin{problem}{III.6.18}
Let $M$ be an $R$-module, and let $N$ be a submodule of $M$. Prove that if $N$ and $M/N$ are both finitely generated, then $M$ is finitely generated.
\end{problem}
\begin{proof}
Let $\{a_i + N\}_{i = 1}^m$ be generators of $M/N$, and $\{b_i\}_{i = 1}^n$ be generators of $N$. Then for every $m \in M$, we consider
\[
m + N = \sum_{i=1}^m r_i (a_i + N) = \sum_{i=1}^m r_i a_i + N
\]
this says that $m - \sum_{i=1}^m r_i a_i \in N$, and therefore we can again write $m - \sum_{i=1}^m r_i a_i = \sum_{j=1}^n s_i b_i$. To this point we showed that every element in $M$ can be generated by $\{a_i,b_j\}_{1 \leq i \leq m, 1 \leq j \leq n}$, showing that $M$ is finitely generated.
\end{proof}

\section{}

\begin{problem}{III.7.1}
Assume that the complex
\[
\begin{tikzcd}
\cdots \arrow[r] &0 \arrow[r] &M \arrow[r] &0 \arrow[r] &\cdots 
\end{tikzcd}
\]
is exact. Prove that $M \cong 0$.
\end{problem}
\begin{proof}
\[
0 = \im (0 \longrightarrow M) = \ker (M \longrightarrow 0) = M.
\]
\end{proof}

\begin{problem}{III.7.2}
Assume that the complex
\[
\begin{tikzcd}
\cdots \arrow[r] &0 \arrow[r] &M \arrow[r] &M' \arrow[r] &0 \arrow[r] &\cdots 
\end{tikzcd}
\]
is exact. Prove that $M \cong M'$.
\end{problem}
\begin{proof}
The map $(M \longrightarrow M')$ is both a monomorphism and an epimorphism by Example III.7.1 and Example III.7.2. By definition, the map is an isomorphism. 
\end{proof}

\begin{problem}{III.7.3}
Assume that the complex
\[
\begin{tikzcd}
\cdots \arrow[r] & 0 \arrow[r] & L \arrow[r] & M \arrow[r, "\varphi"] & M' \arrow[r] & N \arrow[r] & 0 \arrow[r] & \cdots
\end{tikzcd}	
\]
is exact. Show that, up to natural identifications, $L = \ker \varphi$ and $N = \text{coker }\varphi$.
\end{problem}
\begin{proof}
The map $(L \longrightarrow M)$ is a monomorphism, so by canonical decomposition 
\[
L = \frac{L}{\ker (L \longrightarrow M)} \cong \im(L \longrightarrow M) = \ker (M \longrightarrow M') = \ker \varphi.
\]
The map $(M' \longrightarrow N)$ is an epimorphism, so it follows by first isomorphism theorem that
\[
\text{coker }\varphi=\frac{M'}{\im \varphi}=\frac{M'}{\im(M \longrightarrow M')}= \frac{M'}{\ker(M' \longrightarrow N)} \cong N.
\]
\end{proof}

\begin{problem}{III.7.6}
Prove the 'split epimorphism' part of Proposition 7.5, that is,

\textit{$\varphi$ has a right-inverse if and only if the sequence} 
\[
\begin{tikzcd}
0 \arrow[r] & \ker \varphi \arrow[r] & M \arrow[r, "\varphi"] & N \arrow[r] & 0
\end{tikzcd}	
\textit{ splits.}
\]
\end{problem}
\begin{proof} \
\noindent $(\Leftarrow)$ If the sequence splits, then by identifying $\varphi$ with the projection map from $\ker \varphi \oplus N$ to $N$, we can let $\psi : N \to \ker \varphi \oplus N $ to be the inclusion, and it gives a right-inverse. \\
$(\Rightarrow)$ Assume that $\varphi$ has a right inverse, which says that 
\[
\begin{tikzcd}
N \arrow[r, "\psi"] \arrow[rd, "id"'] & M \arrow[d, "\varphi"] \\
& N
\end{tikzcd}	
\]
To prove the statement, we claim that $M \cong \ker \varphi \oplus N$. This isomorphism is given by 
\[
(k,n) \mapsto k + \psi (n)
\]
it has inverse
\[
m \mapsto (m-\psi\varphi(m), \varphi(m))	
\]
Indeed, we check
\[
m \mapsto (m-\psi\varphi(m), \varphi(m)) \mapsto m-\psi\varphi(m) + \psi\varphi(m) = m
\]
and $m-\psi\varphi(m)$ is in $\ker \varphi$ since
\[
\varphi(m-\psi\varphi(m)) = \varphi(m) - \varphi\psi\varphi(m) = 0
\]
and the claim is proved.
\end{proof}

\begin{problem}{III.7.7}
Let
\[
\begin{tikzcd}
0 \arrow[r] &M \arrow[r] &N \arrow[r] &P \arrow[r] &0
\end{tikzcd}
\]
be a short exact sequence of $R$-modules, and let $L$ be an $R$-module.
\begin{enumerate}[label=(\roman*)]
    \setlength\itemsep{0pt}
    \item Prove that there is an exact sequence 
    \[
    \begin{tikzcd}
    0 \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(P,L) \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(N,L) \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(M,L).
    \end{tikzcd}
    \]
    \item Redo Exercise \ref{III.6.17}.
    \item Construct an example showing that the rightmost homomorphism in (i) need not to be onto.
    \item Show that if the original sequence splits, then the rightmost homomorphism in (i) is onto.
\end{enumerate}
\end{problem}
\begin{proof} \
\begin{enumerate}[label=(\roman*)] 
    \setlength\itemsep{0pt}
    \item     
    \[
    \begin{tikzcd}
    0 \arrow[r] &M \arrow[r, "\beta"] &N \arrow[r, "\alpha"] &P \arrow[r] &0
    \end{tikzcd} 
    \]
    \[
    \begin{tikzcd}[column sep=huge]
    0 \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(P,L) \arrow[r, "a(x) = x \circ \alpha"] &\Hom_\mathsf{R\mhyphen Mod}(N,L) \arrow[r, "b(y) = y \circ \beta"] &\Hom_\mathsf{R\mhyphen Mod}(M,L)
    \end{tikzcd}	
    \]
    With definition as above, we show that 
    \[
    \ker a = 0 \quad \text{ and } \quad \im a = \ker b.
    \]
    Clearly $a$ is injective: if $a(x) = a(y)$, then $x \circ \alpha = y \circ \alpha$, and since $\alpha$ is an epimorphism by exactness, $x = y$. For the second part, note by exactness
    \[
    P \cong N/\ker\alpha = N/\im\beta = \text{coker }\beta	
    \]
    which leads us to consider the universal property of cokernels
    \[
    \begin{tikzcd}[column sep=small, row sep=large]
    M \arrow[rr, "0", bend left=40] \arrow[r, "\beta"] & N \arrow[d, "\alpha", two heads] \arrow[r, "y"]                     & L \\
    & P \cong \text{coker }\beta \arrow[ru, "\exists!\varphi"'] &  
    \end{tikzcd}	
    \]
    so for $y \in \ker b$, i.e. $y \circ \beta = 0$, by universal property of cokernel, there is a unique $\varphi: P \to L$ such that $\varphi \circ \alpha = y$, which shows $\ker b \subseteq \im a$. Since the other inclusion is clear (by definition of chain complex), we conclude that $\im a = \ker b$.
    \item The exact sequence
    \[
    \begin{tikzcd}
    0 \arrow[r] & I \arrow[r, "i"] & R \arrow[r, "\pi"] & R/I \cong M \arrow[r] &0
    \end{tikzcd}	
    \]
    with the target $R$-module $N$ yields another exact sequence
    \[
    \begin{tikzcd}
    0 \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(M,N) \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(R,N) \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(I,N)
    \end{tikzcd}
    \]
    by canonical decomposition
    \[
    G = \frac{G}{\ker a} \cong \im a = \ker b
    \]
    and $\ker b$ is
    \[
    \ker \varphi = \{\phi(x)=nx \in \Hom_\mathsf{R\mhyphen Mod}(R, N): \phi \circ i = 0_{\Hom_\mathsf{R\mhyphen Mod}(I, N)}\} \cong \{n \in R: (\forall a \in I)\; an = 0\}
    \]
    as required.
    \item The example
    \[
    \begin{tikzcd}
    0 \arrow[r] &\Z \arrow[r, "\cdot 2"] &\Z \arrow[r, "\pi"] &\Z/2\Z \arrow[r] &0
    \end{tikzcd}
    \]
    yields the exact sequence (with target $\Z$)
    \[
    \begin{tikzcd}
    0 \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(\Z/2\Z,\Z) \arrow[r] &\Hom_\mathsf{R\mhyphen Mod}(\Z,\Z) \arrow[r, "\cdot 2"] &\Hom_\mathsf{R\mhyphen Mod}(\Z,\Z)
    \end{tikzcd}
    \]
    but the last morphism is not surjective as all morphism that is of form $\varphi(x) = nx$ where $n$ is odd is missing in the first $\Hom_\mathsf{R\mhyphen Mod}(\Z,\Z)$.
    \item The map
    \[
    \Hom_\mathsf{R\mhyphen Mod}(M\oplus P,L) \overset{\phi \circ i}{\longrightarrow} \Hom_\mathsf{R\mhyphen Mod}(M,L)
    \]
    is clearly surjective: for each $\varphi: M \to L$, we can find $\varphi': M\oplus P \to L$ defined by $\varphi'((m,p)) = \varphi(m)$, so that the restriction of $\varphi'$ on $M$ is precisely $\varphi$.
\end{enumerate}
\end{proof}

\begin{problem}{III.7.8}
Prove that every exact sequence
\[
\begin{tikzcd}
0 \arrow[r] &M \arrow[r] &N \arrow[r] &F \arrow[r] &0
\end{tikzcd}
\]
of $R$-modules, with $F$ \emph{free}, splits.
\end{problem}
\begin{proof}
By exactness, $\varphi :N \longrightarrow F$ is surjective. Therefore by \ref{III.6.9}, for every $\alpha : F \to F$, there is $\beta : F \to N$ such that $\alpha = \varphi \circ \beta$. In particular, let $\alpha = id_F$, then $\varphi \circ \beta = id_F$. 
\[
\begin{tikzcd}
&  &  & F \arrow[d, "1"] \arrow[ld, "\beta"'] &   \\
0 \arrow[r] & M \arrow[r, "i"] & N \arrow[r, "\varphi"] & F \arrow[r]                           & 0
\end{tikzcd}	
\]
With this, we now show that $M \oplus F \cong N$. Define 
\[
h: M \oplus F \to N, \quad	h(m,f) = i(m) + \beta(f)
\]
$h$ is clearly an $R$-module homomorphism, so it remains to show that it is an isomorphism. $h$ is injective: if $h(m,f) = 0$, then
\[
i(m) + \beta(f) = 0 \; \Rightarrow \varphi i(m) + \varphi \beta (f) = 0 \; \Rightarrow 0 \; (\text{definition of chain complex}) + f = 0
\]
showing that $f = 0$. Then $i(m) = 0$, so we must have $m = 0$. $h$ is surjective: we want to find $m,f$ such that $i(m) + \beta(f) = n$ for $n \in N$. By applying $\varphi$ we have
\[
\varphi i(m) + \varphi \beta (f) = 0 + f = \varphi(n)	
\]
so we have the candidate of $f$. Now it remains to decide $m$ in which $i(m) = n - \beta(\varphi(n))$: notice that by exactness, $\im i = \ker \varphi$, so we check that $\varphi(n - \beta(\varphi(n))) = 0$ to guarantee the existence of $m$:
\[
\varphi(n - \beta(\varphi(n)) = \varphi(n) - \varphi \circ \beta \circ \varphi(n) = \varphi(n) - \varphi(n) = 0
\]
Hence $h$ is an isomorphism, and by definition, the sequence splits.
\end{proof}